{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles y bosques aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es la capacidad de elegir en que cajita va cada elemento, el árbol de desición es un algoritmo supervisado, cuando la variable objetivo a ser clasificada es discreta o categórica ya sea de un solo tipo o de varios tipos a escoger, las predictoras se pueden volver númericas o categóricas, puede ser complicado establecer un conjunto de reglas para ir recorriendo el árbol, desde la raiz hasta los nodos hojas para una variable objetivo para una variable discreta o categórica, esto terminá siendo un conjunto de regas if else que se representan como divisiones, el árbol de decisión se puede ocupar cuando la decisión final esta basada en una serie de pasos escalonados o en pautas que cada vez las variables pueden tomar un valor o otro "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pierde mucha información en variables númericas por que no queda catalogado por ninguna regla de desición, si se usan categorías tienden a ser más seguros los grupos de desición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se pueden crear categorías apartir de los números"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No importa demasiado que la limpieza de datos por que al final se terminan clasificando nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## las matemáticas de un árbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toma una variable e intenta clasificar dependiendo de una serie de valores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogeneidad en los datos\n",
    "Se refiere a que el nodo que separa los datos de otros datos estos datos nuevos agrupados seán lo mayor homegeneos posibles o que no se distinga diferencia entre ellos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Identificar variables que sean lo mas homogeneas posibles en base a algoritmos\n",
    ">** La entropia\n",
    ">\n",
    ">** La ganancia o la perdida de información\n",
    ">\n",
    ">** id3\n",
    ">\n",
    ">** la varianza\n",
    ">\n",
    ">** la moda del arból"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La entropía\n",
    "Utiliza la teoría de información entre más puros son los nodos de un árbol, se requiere menos información para representarlos\n",
    "**Por ejemplo:** Para encriptar una señal, si los elementos que constituyen el mensaje son muy homogeneos en general se consumiran menos bits para llevar acabo la transmisión, la configuración que requiere menos información es la preferida.\n",
    "* **Teoría de la información**\n",
    "Imaginemos que tenemos un mensaje que solo tiene la letra \"a\" y tenemos que codificar un mensaje con 10 \"a\", en vez de enviar las 10 \"a\" si para cada letra necesitariamos los 8 bits, sustituimos por un símbolo, podremos reducir el tamaño de la información, si tenemos 5 \"a\" y 5 \"b\" en vez de enviar su codificación en ascii solo enviariamos el símbolo que corresponde a la letra \"a\" y a la letra \"b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### La impunidad o heterogeneidad\n",
    "Se puede representar de un nodo se puede representar con la entropía, la interpretación de la entropía, la teoría de la información es el número mínimo de bits que hacen falta para codificar una determinidada clasificación de un miembro arbitrario de un conjunto fijado a priori.\n",
    "Cualquier cambio o reducción de una entropia de un nodo se medira como una ganancia.\n",
    "En el arból si añadimos un nodo y este resulta en mayor ganancia de información este se añade a la configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuanto el algoritmo de entropía nos marca, una mayor ganancia, es esta ganancia la que se utiliza como nodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos para crear arboles de desición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las ramas consideradas anteriormente pueden seguir siendo consideradas para el siguiente nodo de ramificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo ID3\n",
    "1. Calculamos la entropia inicial basandonos en la **variable objetivo** a predecir \n",
    "2. Calculamos la ganancia de la información para cada variable candidata para un nodo,\n",
    "Seleccionamos la variable que nos da la máxima, ganancia de información como nodo de desición\n",
    "3. Repetimos el paso dos para cada rama (valor) de cada nodo(variable candidata). El núevo nodo identificado es un nodo hoja\n",
    "4. Comprobamos si el nodo hoja clasifica correctamente todos los datos. Si es así pasaremos con esa rama. si no es así regresamo al paso dos para ramificarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### otros algoritmos\n",
    "* índice Gini: Si la variable a predecir es binaria\n",
    "* Detector Automático de la interacción con Chi Cuadrado(CHAID): Encontrar las diferencias entre un nodo padre y un sunodo hijo, puede gestionar más de dos categorías\n",
    "* Reducción de la varianza: Gestionar el problema de una variable numérica continua como una variable objetivo en un árbol de desición\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La poda de árbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un árbol puede seguir creciendo hasta el infinito creando un problema de oversiting, para evitar que un árbol tenga tantos nodos como muestras del dataset, cuando el árbol aprende de los datos pero los clasifica terriblemente mal cuando se presentan otros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A veces es mejor tener un árbol más pequeño pero que puede clasicar diferentes datasets o información y no solo una información especifica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reducción del error en la poda\n",
    "* Poda del coste de complejidad\n",
    "1. Definir la taza de error para un árbol T en un dataset D err(T,D)\n",
    "2. El número de nodos terminales en el árbol viene dado por leaves \n",
    "3. Definimos la función M como el coeficiente: \n",
    "4. Calculamos M para todos los subarboles de T\n",
    "5. El subárbol que minimiza M se elige para ser eliminado del árbol original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va reduciendo el coste de complejidad, se va reduciendo el número de pasos para llegar a la clasificación pero se va incrementando el error, nosotros debemos ponernos un número para determinar un N máximo para decidir hasta donde el corte, queremos podar el árbol del cual habiamos partido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las variables númericas contínuas o NAs\n",
    "Qué pasa con los valores NAs o nulos \n",
    "* Variables contínuas \n",
    "En el caso de tener variables contínuas hay que encontrar umbrales óptimos de corte para convertirlos a categorías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * Como definimos ese umbral\n",
    "* * 1. Ordenamos los datos de forma ascendente\n",
    "* * 2. Marcamos los rangos de transición de una categoría a otra de la predicada\n",
    "* * 3. Calculamos el punto medio de cada umbral de cambio: C1, C2, C3\n",
    "* * 4. Las categorías serán marcadas por: T<C1, C1<T<C2, C2<T<C3, T>C3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores desaparecidos en el dataset \n",
    "Una de las formas de resolver el problema es asignar el valor más común, de la categoría donde falta una variable o si ya tenemos la predicción echa utilizar el valor que ha predicho en otros casos esa información"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e310ee305116be7a1f6c3fc36efd30b44e9b58a3d111aad7f613c214e7b9dffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
